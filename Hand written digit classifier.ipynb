{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MLlab_week2_411772.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n82B8T8UUeh7",
        "colab_type": "text"
      },
      "source": [
        "Import libraries and  our Data Set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKo519NALBCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.activations import relu,softmax\n",
        "\n",
        "#loading data\n",
        "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20k6GAPhUSPq",
        "colab_type": "text"
      },
      "source": [
        "Data Preprocessing \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIw6xNRwUSnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape dataset to have a single channel with 28x28 pixel size [for using conv2D]\n",
        "# -1 for total length of the data\n",
        "# 28x28 is size of the Image and 1 is channel.\n",
        "train_X = train_X.reshape(-1, 28,28, 1)\n",
        "test_X = test_X.reshape(-1, 28,28, 1)\n",
        "\n",
        "train_X.shape\n",
        "\n",
        "#convert from integers to Floats\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "\n",
        "#Normalize to 0-1  [as color combination 0-255]\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n",
        "# model cannot work with categorical data Directly (0-9 digits)\n",
        "# Use Hot encoding to transfer this data into 0 & 1 using 10 digits (9 zeros,1 one)\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwNIsdYbYXJ-",
        "colab_type": "text"
      },
      "source": [
        "Making Model using Keras Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cptamBgzYXUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "77739d13-dda8-47b3-c9dd-4ba79bcd2019"
      },
      "source": [
        "#Sequential groups a linear stack of layers\n",
        "model = Sequential()\n",
        "\n",
        "#to drop the unecessary data from the image matrix \n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "# to pick the maximum element from the part of image pixel\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "#Flattern is used to convert it into 1D array for next layer Processing\n",
        "model.add(Flatten())\n",
        "\n",
        "# hidden fully connected layer (i.e.Dense) with 100 nodes and relu activation function\n",
        "model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# to drop out data to remove overfitting\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#final output fully connected layer (i.e. Dense) with 10 nides and Softmax activation function\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compile model by adding to optimizer  with adam opt and loss function\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#fitting the data into model with 5 epochs \n",
        "model.fit(x= train_X , y = train_Y , epochs= 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.4723 - accuracy: 0.8328\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.3178 - accuracy: 0.8871\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.2767 - accuracy: 0.8997\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.2503 - accuracy: 0.9089\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.2314 - accuracy: 0.9155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0797a75358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK0tU720fdFc",
        "colab_type": "text"
      },
      "source": [
        "Testing on few data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEh8aTgqfenU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8132ca23-c2d6-458a-d670-8cf5b662da4a"
      },
      "source": [
        "#slicing few data from \n",
        "test_xx = test_X[:30]\n",
        "test_yy = test_Y[:30]\n",
        "\n",
        "#prediction of classes on sample data by our model\n",
        "predicted=model.predict_classes(test_xx,verbose=0)\n",
        "print(\"predictoin and actual values for checking, is the model correct ?\")\n",
        "print(\"predicted:\\t\", predicted) #predicted values\n",
        "print(\"Actual :\\t\",test_yy)    #Actual VAlues"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictoin and actual values for checking, is the model correct ?\n",
            "predicted:\t [9 2 1 1 6 1 4 6 5 7 4 5 8 3 4 1 2 4 8 0 2 5 7 5 1 6 6 0 9 3]\n",
            "Actual :\t [9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ-SfMVHPDm9",
        "colab_type": "text"
      },
      "source": [
        "computing TN, TP, FN, FP for confusion calculation \n",
        "\n",
        "Calculating Precision, Recall, F1 score, Sensitivity, Specificity and Accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cLgkLAmPQvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3ccd7266-538f-4d12-81f7-99fbac98e83b"
      },
      "source": [
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(test_X, verbose=0)\n",
        "\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(test_X, verbose=0)\n",
        "\n",
        "#forming confusion matrix formation for True (test_Y) and Predicted\n",
        "conf_matrix=confusion_matrix(test_Y, yhat_classes)\n",
        "\n",
        "#count for actual value true and prediction is true\n",
        "TP = np.diag(conf_matrix)\n",
        "\n",
        "\n",
        "#count for actual value false but prediction is true\n",
        "FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)\n",
        "\n",
        "#count for actual value true but prediction is false\n",
        "FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
        "\n",
        "#count for actual value false and prediction is false\n",
        "TN = conf_matrix.sum() - (FP + FN + TP)\n",
        "  \n",
        "print(\"TP:\",TP)\n",
        "print(\"TN:\",TN)\n",
        "print(\"FP:\",FP)\n",
        "print(\"FN:\",FN)\n",
        "\n",
        "# Precision or positive predictive value\n",
        "precision = TP/(TP+FP)\n",
        "\n",
        "# Sensitivity, recall, hit rate or true positive rate\n",
        "recall = sensitivity= TP/(TP+FN)\n",
        "\n",
        "# Specificity or true negative rate\n",
        "specificity = TN/(TN+FP) \n",
        "\n",
        "#f1_score \n",
        "F1_scores = 2 * ( (precision * recall) / (precision + recall) )\n",
        "\n",
        "# Overall accuracy\n",
        "acc= (TP+TN)/(TP+FP+FN+TN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP: [835 984 852 951 862 981 703 971 989 960]\n",
            "TN: [8895 8990 8848 8858 8832 8983 8786 8957 8969 8970]\n",
            "FP: [105  10 152 142 168  17 214  43  31  30]\n",
            "FN: [165  16 148  49 138  19 297  29  11  40]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42PfuWoLTRFM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-cYzukiTRsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "629ec111-f56e-4586-ab6e-b4b271ebbea9"
      },
      "source": [
        "# to print in Matrix format making list of columns \n",
        "columns =[precision,specificity,F1_scores,acc,recall]\n",
        "\n",
        "df=pd.DataFrame()\n",
        "\n",
        "i=0 #adding column into data frame to print\n",
        "for col in columns:\n",
        "  df[i]=col\n",
        "  i+=1\n",
        "\n",
        "#printing dataFrame\n",
        "df.columns=['precision','specificity','F1_scores','accuracy','recall=sensitivity']\n",
        "df "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>specificity</th>\n",
              "      <th>F1_scores</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall=sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.888298</td>\n",
              "      <td>0.988333</td>\n",
              "      <td>0.860825</td>\n",
              "      <td>0.9730</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.989940</td>\n",
              "      <td>0.998889</td>\n",
              "      <td>0.986961</td>\n",
              "      <td>0.9974</td>\n",
              "      <td>0.984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.848606</td>\n",
              "      <td>0.983111</td>\n",
              "      <td>0.850299</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.870082</td>\n",
              "      <td>0.984222</td>\n",
              "      <td>0.908743</td>\n",
              "      <td>0.9809</td>\n",
              "      <td>0.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.836893</td>\n",
              "      <td>0.981333</td>\n",
              "      <td>0.849261</td>\n",
              "      <td>0.9694</td>\n",
              "      <td>0.862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.982966</td>\n",
              "      <td>0.998111</td>\n",
              "      <td>0.981982</td>\n",
              "      <td>0.9964</td>\n",
              "      <td>0.981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.766630</td>\n",
              "      <td>0.976222</td>\n",
              "      <td>0.733438</td>\n",
              "      <td>0.9489</td>\n",
              "      <td>0.703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.957594</td>\n",
              "      <td>0.995222</td>\n",
              "      <td>0.964250</td>\n",
              "      <td>0.9928</td>\n",
              "      <td>0.971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.969608</td>\n",
              "      <td>0.996556</td>\n",
              "      <td>0.979208</td>\n",
              "      <td>0.9958</td>\n",
              "      <td>0.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.996667</td>\n",
              "      <td>0.964824</td>\n",
              "      <td>0.9930</td>\n",
              "      <td>0.960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  specificity  F1_scores  accuracy  recall=sensitivity\n",
              "0   0.888298     0.988333   0.860825    0.9730               0.835\n",
              "1   0.989940     0.998889   0.986961    0.9974               0.984\n",
              "2   0.848606     0.983111   0.850299    0.9700               0.852\n",
              "3   0.870082     0.984222   0.908743    0.9809               0.951\n",
              "4   0.836893     0.981333   0.849261    0.9694               0.862\n",
              "5   0.982966     0.998111   0.981982    0.9964               0.981\n",
              "6   0.766630     0.976222   0.733438    0.9489               0.703\n",
              "7   0.957594     0.995222   0.964250    0.9928               0.971\n",
              "8   0.969608     0.996556   0.979208    0.9958               0.989\n",
              "9   0.969697     0.996667   0.964824    0.9930               0.960"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}